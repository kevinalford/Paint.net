{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n",
      "1400 100\n",
      "(1400, 3072)\n",
      "(100, 3072)\n",
      "[0 2 0 2 2 0 2 0 2 0]\n",
      "[1 1 0 2 1 2 2 1 1 1]\n",
      "[112.75133333 107.19333333 101.88266667 ... -39.99466667  -6.972\n",
      "   2.928     ]\n"
     ]
    }
   ],
   "source": [
    "# DATA IN CODE HERE\n",
    "\n",
    "monet = None\n",
    "vangogh = None\n",
    "dali = None\n",
    "picasso = None\n",
    "\n",
    "with open ('monet.pk', 'rb') as fp:\n",
    "    monet = pickle.load(fp)\n",
    "    \n",
    "with open ('vangogh.pk', 'rb') as fp:\n",
    "    vangogh = pickle.load(fp)\n",
    "    \n",
    "with open ('dali.pk', 'rb') as fp:\n",
    "    dali = pickle.load(fp)\n",
    "    \n",
    "with open ('picasso.pk', 'rb') as fp:\n",
    "    picasso = pickle.load(fp)\n",
    "    \n",
    "    \n",
    "print(monet[0].shape)\n",
    "\n",
    "\n",
    "X = np.zeros((1500,32,32,3))\n",
    "y = np.zeros((1500))\n",
    "\n",
    "for pic in range(500):\n",
    "    X[pic] = monet[pic]\n",
    "    y[pic] = 0\n",
    "for pic in range(500):\n",
    "    X[pic + 500] = vangogh[pic]\n",
    "    y[pic + 500] = 1\n",
    "for pic in range(500):\n",
    "    X[pic+ 1000] = dali[pic]\n",
    "    y[pic + 1000] = 2\n",
    "'''\n",
    "for pic in range(100):\n",
    "    X[pic+ 1500] = picasso[pic]\n",
    "    y[pic + 1500] = 3\n",
    "'''\n",
    "#print(X.shape)\n",
    "#print(y.shape)\n",
    "\n",
    "seed = np.random.randint(0, 1000)  \n",
    "\n",
    "np.random.seed(seed)  \n",
    "np.random.shuffle(X)  \n",
    "np.random.seed(seed)  \n",
    "np.random.shuffle(y)\n",
    "\n",
    "mean_image = np.mean(X, axis=0)\n",
    "X -= mean_image\n",
    "\n",
    "X = X.reshape(1500, -1)\n",
    "#X_val = X_val.reshape(num_validation, -1)\n",
    "y = y.astype(int)\n",
    "\n",
    "num_train = 1400\n",
    "num_eval = 100\n",
    "\n",
    "print(num_train, num_eval)\n",
    "\n",
    "X_train = X[range(num_train)]\n",
    "X_eval = np.zeros((num_eval, 3072))\n",
    "y_train = y[range(num_train)]\n",
    "y_eval = np.zeros(num_eval).astype(int)\n",
    "\n",
    "for i in range(num_eval):\n",
    "    X_eval[i] = X[i + num_train]\n",
    "    y_eval[i] = y[i + num_train]\n",
    "\n",
    " \n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_eval.shape)\n",
    "print(y_train[:10])\n",
    "print(y_eval[:10])\n",
    "\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch  5  the loss is:  1.348273822558491\n",
      "At epoch  10  the loss is:  1.3138751873117467\n",
      "At epoch  15  the loss is:  1.2886672519195936\n",
      "At epoch  20  the loss is:  1.274285144750488\n",
      "At epoch  25  the loss is:  1.2703718206099535\n",
      "At epoch  30  the loss is:  1.2487181469012316\n",
      "At epoch  35  the loss is:  1.2275489730576095\n",
      "At epoch  40  the loss is:  1.224036337696038\n",
      "At epoch  45  the loss is:  1.207411106678412\n",
      "At epoch  50  the loss is:  1.206573013970069\n"
     ]
    }
   ],
   "source": [
    "def relu(array):\n",
    "    return np.maximum(0, array)\n",
    "def sigmoid(array):\n",
    "    return 1 / (1 + np.exp(-array))\n",
    "\n",
    "\n",
    "epoch = 10\n",
    "learning_rate = .0005\n",
    "batch_size = 50\n",
    "N = batch_size\n",
    "reg = 5e-3\n",
    "\n",
    "input_size = N\n",
    "output_size = 4\n",
    "hidden1 = 16\n",
    "hidden2 = 16\n",
    "\n",
    "W1 = np.random.rand(X.shape[1], hidden1) * 1e-2\n",
    "b1 = np.zeros(hidden1)\n",
    "W2 = np.random.rand(hidden1, hidden2) * 1e-2\n",
    "b2 = np.zeros(hidden2)\n",
    "W3 = np.random.rand(hidden2, output_size) * 1e-2\n",
    "b3 = np.zeros(output_size)\n",
    "\n",
    "for i in range(50):\n",
    "    loss = 0\n",
    "    for j in range(25):\n",
    "        \n",
    "        indices = np.random.choice(X_train.shape[0], batch_size)\n",
    "        X_curr = X_train[indices]\n",
    "        y_curr = y_train[indices]\n",
    "        #print(X_curr)\n",
    "        \n",
    "        layer1 = X_curr.dot(W1) + b1\n",
    "        max_layer1 = np.maximum(0,layer1)\n",
    "        layer2 = max_layer1.dot(W2) + b2\n",
    "        max_layer2 = sigmoid(layer2)\n",
    "        #max_layer2 = np.maximum(0, layer2)\n",
    "        scores = max_layer2.dot(W3) + b3\n",
    "        \n",
    "        exp_scores = np.exp(scores)\n",
    "        exp_scores_sum = np.sum(exp_scores, axis = 1, keepdims=True)\n",
    "        softmax = exp_scores / exp_scores_sum\n",
    "        \n",
    "        \n",
    "        loss = np.sum(-np.log(softmax[range(N), y_curr]))\n",
    "        loss /= N\n",
    "        loss += reg * (np.sum(W1**2) + np.sum(W2**2) + np.sum(W3**2))\n",
    "        \n",
    "        \n",
    "        \n",
    "        W3_grads = softmax\n",
    "        W3_grads[range(X_curr.shape[0]), y_curr] -= 1\n",
    "        W2_grads = W3_grads.dot(W3.T) * max_layer2 * (1 - max_layer2)\n",
    "        W1_grads = W2_grads.dot(W2.T) * (layer1 > 0)\n",
    "        \n",
    "        gW3 = max_layer2.T.dot(W3_grads) / N\n",
    "        gb3 = np.sum(W3_grads, axis = 0) / N\n",
    "        gW2 = max_layer1.T.dot(W2_grads) / N\n",
    "        gb2 = np.sum(W2_grads, axis = 0) / N\n",
    "        gW1 = X_curr.T.dot(W1_grads) / N\n",
    "        gb1 = np.sum(W1_grads, axis = 0) / N\n",
    "        \n",
    "        \n",
    "        gW3 += W3 * reg #* 2\n",
    "        gW2 += W2 * reg #* 2\n",
    "        gW1 += W1 * reg #* 2\n",
    "        \n",
    "        \n",
    "        \n",
    "        W1 += -learning_rate * gW1\n",
    "        b1 += -learning_rate * gb1\n",
    "        W2 += -learning_rate * gW2\n",
    "        b2 += -learning_rate * gb2\n",
    "        W3 += -learning_rate * gW3\n",
    "        b3 += -learning_rate * gb3\n",
    "        \n",
    "        \n",
    "        #print(loss)\n",
    "        #print(\"\\n\\n\")\n",
    "    if (i+1) % 5 == 0:\n",
    "        print(\"At epoch \", i+1, \" the loss is: \", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Percent Correct is  0.48\n"
     ]
    }
   ],
   "source": [
    "#PREDICT\n",
    "\n",
    "layer1 = X_eval.dot(W1) + b1\n",
    "max_layer1 = np.maximum(0, layer1)\n",
    "layer2 = layer1.dot(W2) + b2\n",
    "max_layer2 = relu(layer2)\n",
    "scores = max_layer2.dot(W3) + b3\n",
    "\n",
    "exp_scores = np.exp(scores)\n",
    "exp_scores_sum = np.sum(exp_scores, axis = 1, keepdims=True)\n",
    "softmax = exp_scores / exp_scores_sum\n",
    "\n",
    "ans = np.argmax(softmax, axis = 1)\n",
    "#print(softmax)\n",
    "#print(ans)\n",
    "\n",
    "correct = 0\n",
    "for i in range(ans.shape[0]):\n",
    "    \n",
    "    if ans[i] == y_eval[i]:\n",
    "        correct += 1\n",
    "correct = correct / y_eval.shape[0]\n",
    "    \n",
    "print(\"The Percent Correct is \", correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
